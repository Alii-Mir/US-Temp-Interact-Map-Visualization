Encode:
- Tokens: smaller units of a text document
- Embedding: a mathematical representation of a word in a numerical vector
- Transformer: a specific type of NN to process sequential data

- Recurrent NN includes weighted connections within a layer

- Decoder: responsible for processing the structured encoding generated by the encoder and producing the output sequence


- TextBlob, NLTK, Pattern: NLP libraries in Python
=========================================================================================================================================

- Zero-shot prompting: a technique where NLP model can generate responses without being explicitly trained on the specific task/prompt
	Prompt: "Translate the following English sentence to Spanish: 
	'Hello, how are you feeling today?'"


- Chain-of-thought prompting: "Let's think step by step": e.g. complex math calculations


- Generated knowledge prompting: Instructing a language model to first generate relevant information/knowledge before responding to a query


- Retrieval augmented generation (RAG) prompting: possess the ability to research and contextualize information; to handle knowledge-intensive tasks
	RAG uses the input to retrieve a set of relevant documents/info. Solves no source and out of date problems in answering by
	incorporating information from external (non-trained) knowledge sources.
=========================================================================================================================================
